{"ast":null,"code":"import { createCommentVNode as _createCommentVNode, createElementVNode as _createElementVNode, vModelText as _vModelText, withKeys as _withKeys, withDirectives as _withDirectives, openBlock as _openBlock, createElementBlock as _createElementBlock } from \"vue\";\nconst _hoisted_1 = {\n  class: \"app\"\n};\nconst _hoisted_2 = {\n  ref: \"liveCanvas\"\n};\nconst _hoisted_3 = [\"value\"];\nexport function render(_ctx, _cache, $props, $setup, $data, $options) {\n  return _openBlock(), _createElementBlock(\"div\", _hoisted_1, [_createCommentVNode(\" 自定义ref=\\\"liveCanvas\\\"： \"), _createElementVNode(\"canvas\", _hoisted_2, null, 512 /* NEED_PATCH */), _createCommentVNode(\" 用户输入框 \"), _withDirectives(_createElementVNode(\"textarea\", {\n    \"onUpdate:modelValue\": _cache[0] || (_cache[0] = $event => $data.userQuestion = $event),\n    class: \"transparent-textarea\",\n    placeholder: \"输入你的问题...\",\n    onKeydown: _cache[1] || (_cache[1] = _withKeys((...args) => $options.sendQuestion && $options.sendQuestion(...args), [\"enter\"]))\n  }, null, 544 /* NEED_HYDRATION, NEED_PATCH */), [[_vModelText, $data.userQuestion]]), _createCommentVNode(\" AI响应展示 \"), _createElementVNode(\"textarea\", {\n    value: $data.aiResponse,\n    class: \"response-textarea\",\n    placeholder: \"AI的回复...\",\n    readonly: \"\"\n  }, null, 8 /* PROPS */, _hoisted_3), _createCommentVNode(\" 新增表情切换按钮 \"), $data.model ? (_openBlock(), _createElementBlock(\"button\", {\n    key: 0,\n    class: \"expression-btn_1\",\n    onClick: _cache[2] || (_cache[2] = $event => $options.changeExpression('1desk'))\n  }, \" 重置表情😀 \")) : _createCommentVNode(\"v-if\", true), $data.model ? (_openBlock(), _createElementBlock(\"button\", {\n    key: 1,\n    class: \"expression-btn_2\",\n    onClick: _cache[3] || (_cache[3] = $event => $options.changeExpression())\n  }, \" 随机表情🤩 \")) : _createCommentVNode(\"v-if\", true), $data.model ? (_openBlock(), _createElementBlock(\"button\", {\n    key: 2,\n    class: \"expression-btn_3\",\n    onClick: _cache[4] || (_cache[4] = $event => $options.change_test())\n  }, \" 测试按钮 \")) : _createCommentVNode(\"v-if\", true)]);\n}","map":{"version":3,"names":["class","ref","_createElementBlock","_hoisted_1","_createCommentVNode","_createElementVNode","_hoisted_2","_cache","$event","$data","userQuestion","placeholder","onKeydown","_withKeys","args","$options","sendQuestion","value","aiResponse","readonly","_hoisted_3","model","key","onClick","changeExpression","change_test"],"sources":["/home/fan/docker_image/live2d/demo/src/App.vue"],"sourcesContent":["<script>\n// 引入必要的库\nimport * as PIXI from 'pixi.js';\nimport { Live2DModel } from 'pixi-live2d-display/cubism4';\nwindow.PIXI = PIXI; // 为了pixi-live2d-display内部调用\nlet app; // 用于存储pixi实例\n//let model; // 用于存储live2d实例\n\nexport default {\n  data() {\n    return {\n      userQuestion: '',\n      aiResponse: '',\n      ws: null,\n      audioUrl: '',\n      fullResponse: '', // 新增：用于累积完整响应\n      model: null, // 将model移到data中以便Vue响应式管理\n    };\n  },\n\n  async mounted() {\n    app = new PIXI.Application({\n      view: this.$refs.liveCanvas, // ref组件绑定，liveCanvas为下文自定义的\n      autoStart: true,             // 是否开启自动播放\n      resizeTo: window,\n      backgroundAlpha: 0,         // 透明度\n    });\n\n    // 将model实例保存到组件data中\n    this.model = await Live2DModel.from('character/U.model3.json',{\n      // 展示工具箱（可以控制 live2d 的展出隐藏，使用特定表情）\n      ShowToolBox: false,\n\n    // 是否使用 indexDB 进行缓存优化，这样下一次载入就不会再发起网络请求了\n      LoadFromCache: true,\n      autoInteract: false, // 关闭眼睛自动跟随功能\n    });\n    this.model.x = 500;\n    this.model.y = 100;\n    this.model.scale.set(1);\n    app.stage.addChild(this.model);\n    this.model.expression('桌');\n  },\n\n  methods: {\n    // 新增表情切换方法\n    changeExpression(text) {\n      if (this.model) {\n        this.model.expression(text);\n      }\n    },\n\n    change_test() {\n      setInterval(() => {\n        let n = Math.random();\n        console.log(\"随机数0~1控制嘴巴Y轴高度-->\", n);\n        this.model.internalModel.coreModel.setParameterValueById(\"ParamMouthOpenY\", n);\n      }, 100);\n    },\n\n    async sendQuestion(e) {\n      e.preventDefault();\n      if (!this.userQuestion.trim()) return;\n\n      // 清空之前的回复\n      this.aiResponse = ''; // 清空响应内容\n\n      // 确保连接可用\n      if (!this.ws || this.ws.readyState === WebSocket.CLOSED) {\n        await this.initWebSocket();\n      }\n\n      // 确保连接已建立\n      if (this.ws.readyState === WebSocket.CONNECTING) {\n        await new Promise((resolve) => {\n          this.ws.addEventListener('open', resolve);\n        });\n      }\n\n      // 发送消息\n      if (this.ws.readyState === WebSocket.OPEN) {\n        this.ws.send(this.userQuestion);\n        this.userQuestion = '';\n      } else {\n        console.error('WebSocket连接异常状态:', this.ws.readyState);\n        this.aiResponse = \"连接异常，请刷新页面重试\";\n      }\n    },\n\n    initWebSocket() {\n      return new Promise((resolve) => {\n        if (this.ws) {\n          this.ws.close(); // 关闭旧连接\n        }\n\n        this.ws = new WebSocket('ws://localhost:4600/question');\n        \n         // 修改后的消息监听\n         this.ws.addEventListener('message', (event) => {\n          const response = JSON.parse(event.data);\n          \n          // 处理错误情况\n          if (response.error) {\n            this.aiResponse = response.error;\n            return;\n          }\n          this.model.expression('敲键盘');  // 开始回复时切换表情\n          // 如果是第一次收到回复，切换为“敲键盘”表情\n         // if (this.aiResponse === '') {\n         //   this.model.expression('敲键盘');  // 开始回复时切换表情\n         //}\n\n          // 累积响应内容\n          if (response.data) {\n            this.aiResponse += response.data;\n            this.fullResponse += response.data; // 累积完整响应\n          }\n\n          // 自动滚动\n          this.$nextTick(() => {\n            const textarea = this.$el.querySelector('.response-textarea');\n            textarea.scrollTop = textarea.scrollHeight;\n          });\n\n          // 新增：仅在收到结束标记时触发语音合成\n          if (response.isEnd) {\n            const cleanText = this.fullResponse\n              .replace(/<think>[\\s\\S]*?<\\/think>/g, '')\n              .replace(/[A-Za-z*]/g, '')\n              .trim();\n\n            if (cleanText) {\n              this.convertTextToSpeech(cleanText);\n            }\n            \n            this.fullResponse = ''; // 清空累积内容\n            // 回复完全结束，切换为“桌”表情\n            this.model.expression('桌');\n          }\n        });\n        \n        this.ws.addEventListener('open', () => {\n          console.log('WebSocket连接已建立');\n          resolve();\n        });\n\n        // 错误处理增强\n        this.ws.addEventListener('error', (error) => {\n          console.error('WebSocket错误:', error);\n          this.aiResponse = \"连接出现错误，请检查控制台\";\n        });\n\n        // 关闭处理\n        this.ws.addEventListener('close', () => {\n          console.log('WebSocket连接已关闭');\n          this.ws = null; // 重要！重置连接实例\n        });\n      });\n    },\n    \n    // 修改后的语音合成方法\n    async convertTextToSpeech(text) {\n      try {\n        const response = await fetch(\n          `http://localhost:4500/generate-tts?text=${encodeURIComponent(text)}`\n        );\n        const data = await response.json();\n        \n        if (data.audioUrl) {\n          this.playAudio(data.audioUrl);\n        } else {\n          console.error('音频生成失败:', data.error);\n        }\n      } catch (error) {\n        console.error('语音转换错误:', error);\n        this.aiResponse += '\\n[语音转换失败]';\n      }\n    },\n\n    playAudio(audioUrl) {\n      // 创建音频上下文\n      const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      \n      // 获取音频数据\n      fetch(audioUrl)\n        .then(response => response.arrayBuffer())\n        .then(audioData => audioContext.decodeAudioData(audioData))\n        .then(audioBuffer => {\n          // 创建音频节点\n          const source = audioContext.createBufferSource();\n          const analyser = audioContext.createAnalyser();\n          \n          // 配置分析器\n          analyser.fftSize = 256;\n          source.buffer = audioBuffer;\n          \n          // 连接音频节点\n          source.connect(analyser);\n          analyser.connect(audioContext.destination);\n          \n          // 初始化动画参数\n          let requestId = null;\n          const dataArray = new Uint8Array(analyser.frequencyBinCount);\n\n          // 启动音频播放\n          source.start(0);\n\n          // 创建动画循环\n          const updateMouth = () => {\n            analyser.getByteFrequencyData(dataArray);\n            \n            // 计算平均音量\n            const volume = dataArray.reduce((a, b) => a + b) / dataArray.length;\n            const mouthOpen = Math.min(1, volume / 180); // 调整除数可改变灵敏度\n            \n            // 更新模型参数\n            this.model.internalModel.coreModel.setParameterValueById(\n              \"ParamMouthOpenY\",\n              mouthOpen\n            );\n            \n            requestId = requestAnimationFrame(updateMouth);\n          };\n\n          // 启动动画\n          requestId = requestAnimationFrame(updateMouth);\n\n          // 音频结束时清理\n          source.onended = () => {\n            cancelAnimationFrame(requestId);\n            this.model.internalModel.coreModel.setParameterValueById(\n              \"ParamMouthOpenY\",\n              0\n            );\n            audioContext.close();\n          };\n        })\n        .catch(error => {\n          console.error('音频处理错误:', error);\n          this.model.internalModel.coreModel.setParameterValueById(\n            \"ParamMouthOpenY\",\n            0\n          );\n        });\n    }\n  }\n}\n</script>\n\n<template>\n  <div class=\"app\">\n    <!-- 自定义ref=\"liveCanvas\"： -->\n    <canvas ref=\"liveCanvas\"></canvas>\n\n    <!-- 用户输入框 -->\n    <textarea\n      v-model=\"userQuestion\"\n      class=\"transparent-textarea\"\n      placeholder=\"输入你的问题...\"\n      @keydown.enter=\"sendQuestion\"\n    ></textarea>\n    \n    <!-- AI响应展示 -->\n    <textarea\n      :value=\"aiResponse\"\n      class=\"response-textarea\"\n      placeholder=\"AI的回复...\"\n      readonly\n    ></textarea>\n\n    <!-- 新增表情切换按钮 -->\n    <button \n      class=\"expression-btn_1\"\n      @click=\"changeExpression('1desk')\"\n      v-if=\"model\" \n    >\n      重置表情😀\n    </button>\n\n      <button \n      class=\"expression-btn_2\"\n      @click=\"changeExpression()\"\n      v-if=\"model\" \n    >\n      随机表情🤩\n    </button>\n\n    <button \n      class=\"expression-btn_3\"\n      @click=\"change_test()\"\n      v-if=\"model\" \n    >\n      测试按钮\n    </button>\n  </div>\n</template>\n\n<style scoped>\n.app {\n  background-image: url('/public/picture/behind02.jpg'); /* 设置背景图片 */\n  background-size: cover; /* 确保图片覆盖整个容器 */\n  background-position: center; /* 居中显示图片 */\n  background-attachment: fixed; /* 背景固定 */\n  height: 100vh; /* 高度设置为视口高度，确保背景覆盖整个页面 */\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  position: relative; /* 使得可以相对定位其他元素 */\n}\n\n.transparent-textarea {\n  position: absolute;\n  bottom: 7%; /* 设置距离页面底部的距离，使其在中间偏下 */\n  left: 50%; /* 水平居中 */\n  transform: translateX(-50%); /* 调整以确保输入框完全居中 */\n  padding: 10px;\n  font-size: 20px;\n  background-color: rgba(255, 255, 255, 0.8); /* 背景透明度50% */\n  border: 1px solid rgba(0, 0, 0, 0.3); /* 边框稍微透明 */\n  border-radius: 5px; /* 圆角 */\n  color: #333; /* 文本颜色 */\n  width: 60%; /* 宽度可以根据需要调整 */\n  min-height: 100px; /* 设置最小高度，使文本框足够高以容纳多行文本 */\n  resize: none; /* 禁止用户调整文本框大小 */\n  overflow: auto; /* 内容溢出时显示滚动条 */\n  white-space: pre-wrap; /* 保证文本在遇到长单词或链接时自动换行 */\n}\n\n.response-textarea {\n  position: absolute;\n  right: 4%; /* 设置距离页面右侧的距离 */\n  top: 20%; /* 设置距离页面顶部的距离 */\n  padding: 10px;\n  font-size: 16px;\n  background-color: rgba(255, 255, 255, 0.8); /* 背景透明度50% */\n  border: 1px solid rgba(0, 0, 0, 0.3); /* 边框稍微透明 */\n  border-radius: 5px; /* 圆角 */\n  color: #333; /* 文本颜色 */\n  width: 25%; /* 宽度可以根据需要调整 */\n  min-height: 400px; /* 设置最小高度 */\n  resize: none; /* 禁止用户调整文本框大小 */\n  overflow: auto; /* 内容溢出时显示滚动条 */\n  white-space: pre-wrap; /* 保证文本在遇到长单词或链接时自动换行 */\n}\n\n.expression-btn_1 {\n  position: absolute;\n  right: 18.1%;\n  top: 63%;\n  padding: 12px 24px;\n  font-size: 20px;\n  width: 12%;\n  background-color: rgba(106, 240, 128, 0.9);\n  border: none;\n  border-radius: 25px;\n  color: rgb(0, 0, 0);\n  cursor: pointer;\n  transition: all 0.3s ease;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n}\n\n.expression-btn_2 {\n  position: absolute;\n  right: 4%;\n  top: 63%;\n  padding: 12px 24px;\n  font-size: 20px;\n  width: 12%;\n  background-color: rgba(106, 240, 128, 0.9);\n  border: none;\n  border-radius: 25px;\n  color: rgb(0, 0, 0);\n  cursor: pointer;\n  transition: all 0.3s ease;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n}\n\n.expression-btn_3 {\n  position: absolute;\n  right: 12%;\n  top: 70%;\n  padding: 12px 24px;\n  font-size: 20px;\n  width: 10%;\n  background-color: rgba(106, 179, 240, 0.9);\n  border: none;\n  border-radius: 25px;\n  color: white;\n  cursor: pointer;\n  transition: all 0.3s ease;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n}\n\n</style>\n"],"mappings":";;EA0POA,KAAK,EAAC;AAAK;;EAENC,GAAG,EAAC;AAAY;mBA5P5B;;uBA0PEC,mBAAA,CA4CM,OA5CNC,UA4CM,GA3CJC,mBAAA,4BAA6B,EAC7BC,mBAAA,CAAkC,UAAlCC,UAAkC,+BAElCF,mBAAA,WAAc,E,gBACdC,mBAAA,CAKY;IApQhB,uBAAAE,MAAA,QAAAA,MAAA,MAAAC,MAAA,IAgQeC,KAAA,CAAAC,YAAY,GAAAF,MAAA;IACrBR,KAAK,EAAC,sBAAsB;IAC5BW,WAAW,EAAC,WAAW;IACtBC,SAAO,EAAAL,MAAA,QAAAA,MAAA,MAnQdM,SAAA,KAAAC,IAAA,KAmQsBC,QAAA,CAAAC,YAAA,IAAAD,QAAA,CAAAC,YAAA,IAAAF,IAAA,CAAY;iEAHnBL,KAAA,CAAAC,YAAY,E,GAMvBN,mBAAA,YAAe,EACfC,mBAAA,CAKY;IAJTY,KAAK,EAAER,KAAA,CAAAS,UAAU;IAClBlB,KAAK,EAAC,mBAAmB;IACzBW,WAAW,EAAC,UAAU;IACtBQ,QAAQ,EAAR;0BA3QNC,UAAA,GA8QIhB,mBAAA,cAAiB,EAITK,KAAA,CAAAY,KAAK,I,cAHbnB,mBAAA,CAMS;IArRboB,GAAA;IAgRMtB,KAAK,EAAC,kBAAkB;IACvBuB,OAAK,EAAAhB,MAAA,QAAAA,MAAA,MAAAC,MAAA,IAAEO,QAAA,CAAAS,gBAAgB;KAEzB,UAED,KArRJpB,mBAAA,gBA0RYK,KAAA,CAAAY,KAAK,I,cAHXnB,mBAAA,CAMO;IA7RboB,GAAA;IAwRMtB,KAAK,EAAC,kBAAkB;IACvBuB,OAAK,EAAAhB,MAAA,QAAAA,MAAA,MAAAC,MAAA,IAAEO,QAAA,CAAAS,gBAAgB;KAEzB,UAED,KA7RJpB,mBAAA,gBAkSYK,KAAA,CAAAY,KAAK,I,cAHbnB,mBAAA,CAMS;IArSboB,GAAA;IAgSMtB,KAAK,EAAC,kBAAkB;IACvBuB,OAAK,EAAAhB,MAAA,QAAAA,MAAA,MAAAC,MAAA,IAAEO,QAAA,CAAAU,WAAW;KAEpB,QAED,KArSJrB,mBAAA,e","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}